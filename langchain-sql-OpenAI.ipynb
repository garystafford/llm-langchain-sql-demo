{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LangChain and LLMs to Analyze Data in Amazon RDS\n",
    "\n",
    "Demonstration of [LangChain SQL Chain](https://python.langchain.com/en/latest/modules/chains/examples/sqlite.html) (`SQLDatabaseChain` and `SQLDatabaseSequentialChain`) and [SQL Database Agent](https://python.langchain.com/en/latest/modules/agents/toolkits/examples/sql_database.html) to analyze the data in an [Amazon RDS for PostgreSQL](https://aws.amazon.com/rds/postgresql/) database. Demonstration uses OpenAI's LLMs.\n",
    "\n",
    "Author: Gary A. Stafford  \n",
    "Date: 2023-05-29  \n",
    "License: MIT  \n",
    "Kernal: `conda_python3`  \n",
    "References:\n",
    "- [LangChain Documentation: SQL Chain example](https://python.langchain.com/en/latest/modules/chains/examples/sqlite.html#sql-chain-example)\n",
    "- [LangChain Blog: LLMs and SQL](https://blog.langchain.dev/llms-and-sql/)\n",
    "- [How do davinci and text-davinci-003 differ?\n",
    "](https://help.openai.com/en/articles/6643408-how-do-davinci-and-text-davinci-003-differ)\n",
    "- [How do text-davinci-002 and text-davinci-003 differ?\n",
    "](https://help.openai.com/en/articles/6779149-how-do-text-davinci-002-and-text-davinci-003-differ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "1. Import the [The Museum of Modern Art (MoMA) Collection database](https://github.com/MuseumofModernArt/collection), found on GitHub, into an [Amazon RDS for PostgreSQL](https://aws.amazon.com/rds/postgresql/) database. Make sure your RDS instance is accessible to your SageMaker Notebook environment.\n",
    "\n",
    "2. `git clone` this post's GitHub project to your Amazon SageMaker notebook instance.\n",
    "\n",
    "3. Create or update the `.env` file, used by `dotenv`, using the terminal in your SageMaker Notebook environment. Add your RDS database credentials to the file: `RDS_ENDPOINT`, `RDS_PORT`, `RDS_USERNAME`, `RDS_PASSWORD`, `RDS_DB_NAME`. See this post's GitHub project for an example. __NOTE__: credentials will be stored in plain text. The recommended, more secure method is to use [AWS Secrets Manager](https://docs.aws.amazon.com/secretsmanager/latest/userguide/intro.html).\n",
    "\n",
    "4. Create a OpenAI account and update the `.env` file to include your OpenAI API Key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: update pip\n",
    "%pip install pip -Uq\n",
    "\n",
    "# Install the latest versions of langchain and openai\n",
    "%pip install langchain openai -Uq\n",
    "\n",
    "# Install latest versions of other required packages\n",
    "%pip install ipywidgets awscli boto3 python-dotenv SQLAlchemy psycopg2 psycopg2-binary -Uq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check verions of LangChain and OpenAI\n",
    "%pip list | grep 'langchain\\|openai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, os, json, psycopg2\n",
    "from langchain import SQLDatabase, SQLDatabaseChain, OpenAI\n",
    "from langchain.chains import SQLDatabaseSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid the error:\n",
    "# huggingface/tokenizers: The current process just got forked, after parallelism has already been used.\n",
    "# Disabling parallelism to avoid deadlocks...\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Environment Variable\n",
    "\n",
    "Use `dotenv` to load the OpenAI and RDS environment variable. __NOTE__: credentials will be stored in plain text. The recommended, more secure method is to use [AWS Secrets Manager](https://docs.aws.amazon.com/secretsmanager/latest/userguide/intro.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load env vars from .env file\n",
    "%load_ext dotenv\n",
    "# %reload_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLAlchemy 2.0\n",
    "# https://docs.sqlalchemy.org/en/20/dialects/postgresql.html\n",
    "# uri format: postgresql+psycopg2://user:psw@hostname:port/dbname\n",
    "\n",
    "RDS_DB_NAME = os.environ.get(\"RDS_DB_NAME\")\n",
    "RDS_ENDPOINT = os.environ.get(\"RDS_ENDPOINT\")\n",
    "RDS_PASSWORD = os.environ.get(\"RDS_PASSWORD\")\n",
    "RDS_PORT = os.environ.get(\"RDS_PORT\")\n",
    "RDS_USERNAME = os.environ.get(\"RDS_USERNAME\")\n",
    "RDS_URI = f\"postgresql+psycopg2://{RDS_USERNAME}:{RDS_PASSWORD}@{RDS_ENDPOINT}:{RDS_PORT}/{RDS_DB_NAME}\"\n",
    "\n",
    "print(RDS_URI.replace(RDS_PASSWORD, \"********\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LangChain OpenAI\n",
    "\n",
    "Use OpenAI's `text-davinci-003` LLM. See https://platform.openai.com/docs/models/overview for model information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LangChain's SQL Chain\n",
    "\n",
    "Next, we will use LangChain's [SQLDatabaseChain](https://python.langchain.com/en/latest/modules/chains/examples) and [SQLDatabaseSequentialChain](https://python.langchain.com/en/latest/modules/chains/examples/sqlite.html#sqldatabasesequentialchain) for answering questions of the MoMA database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A few sample questions\n",
    "QUESTION_01 = \"How many artists are there?\"\n",
    "QUESTION_02 = \"How many artworks are there?\"\n",
    "QUESTION_03 = \"How many rows are in the artists table?\"\n",
    "QUESTION_04 = \"How many rows are in the artworks table?\"\n",
    "QUESTION_05 = \"How many artists are there where nationality is French?\"\n",
    "QUESTION_06 = \"How many artworks were created by artists whose nationality is Spanish?\"\n",
    "QUESTION_07 = \"How many artist names start with 'M'?\"\n",
    "QUESTION_08 = \"What nationality produced the most number of artworks?\"\n",
    "QUESTION_09 = \"How many artworks are by Claude Monet?\"\n",
    "QUESTION_10 = \"SELECT artist_id, name, nationality, gender, birth_year, death_year FROM artists LIMIT 10;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reference: https://python.langchain.com/en/latest/modules/chains/examples/sqlite.html#sqldatabasesequentialchain\n",
    "from sqlalchemy.exc import ProgrammingError\n",
    "\n",
    "db = SQLDatabase.from_uri(RDS_URI)\n",
    "\n",
    "db_chain = SQLDatabaseSequentialChain.from_llm(\n",
    "    llm, db, verbose=True, use_query_checker=True\n",
    ")\n",
    "\n",
    "try:\n",
    "    db_chain.run(QUESTION_06)\n",
    "except (ProgrammingError, ValueError) as exc:\n",
    "    print(f\"\\n\\n{exc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Options: Custom Table Info and Query Checker\n",
    "\n",
    "According to LangChain's [documentation](https://python.langchain.com/en/latest/modules/chains/examples/sqlite.html#custom-table-info), \"_In some cases, it can be useful to provide custom table information instead of using the automatically generated table definitions and the first sample_rows_in_table_info sample rows._\" Of course, this is impractical when dealing with a large number of tables.\n",
    "\n",
    "According to LangChain's [documentation](https://python.langchain.com/en/latest/modules/chains/examples/sqlite.html#adding-example-rows-from-each-table), \"_Sometimes the Language Model generates invalid SQL with small mistakes that can be self-corrected using the same technique used by the SQL Database Agent to try and fix the SQL using the LLM._\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_table_info = {\n",
    "    \"artists\": \"\"\"CREATE TABLE artists (\n",
    "        artist_id integer NOT NULL,\n",
    "        name character varying(200)\",\n",
    "        nationality character varying(50)\",\n",
    "        gender character varying(25)\",\n",
    "        birth_year integer,\n",
    "        death_year integer,\n",
    "        CONSTRAINT artists_pk PRIMARY KEY (artist_id)\n",
    ")\n",
    "\n",
    "/*\n",
    "3 rows from artists table:\n",
    "\"artist_id\"\t\"name\"\t\"nationality\"\t\"gender\"\t\"birth_year\"\t\"death_year\"\n",
    "12\t\"Jüri Arrak\"\t\"Estonian\"\t\"Male\"\t1936\t\n",
    "19\t\"Richard Artschwager\"\t\"American\"\t\"Male\"\t1923\t2013\n",
    "22\t\"Isidora Aschheim\"\t\"Israeli\"\t\"Female\"\t\t\n",
    "*/\"\"\",\n",
    "    \"artworks\": \"\"\"CREATE TABLE artworks (\n",
    "        artwork_id integer NOT NULL,\n",
    "        title character varying(500)\",\n",
    "        artist_id integer NOT NULL,\n",
    "        name character varying(500)\",\n",
    "        date integer,\n",
    "        medium character varying(250)\",\n",
    "        dimensions text\",\n",
    "        acquisition_date text\",\n",
    "        credit text\",\n",
    "        catalogue character varying(250)\",\n",
    "        department character varying(250)\",\n",
    "        classification character varying(250)\",\n",
    "        object_number text\",\n",
    "        diameter_cm text\",\n",
    "        circumference_cm text\",\n",
    "        height_cm text\",\n",
    "        length_cm text\",\n",
    "        width_cm text\",\n",
    "        depth_cm text\",\n",
    "        weight_kg text\",\n",
    "        durations integer,\n",
    "        CONSTRAINT artworks_pk PRIMARY KEY (artwork_id)\n",
    ")\n",
    "\n",
    "/*\n",
    "3 rows from artworks table:\n",
    "\"artwork_id\"\t\"title\"\t\"artist_id\"\t\"name\"\t\"date\"\t\"medium\"\t\"dimensions\"\t\"acquisition_date\"\t\"credit\"\t\"catalogue\"\t\"department\"\t\"classification\"\t\"object_number\"\t\"diameter_cm\"\t\"circumference_cm\"\t\"height_cm\"\t\"length_cm\"\t\"width_cm\"\t\"depth_cm\"\t\"weight_kg\"\t\"durations\"\n",
    "102312\t\"Watching the Game\"\t2422\t\"John Gutmann\"\t1934\t\"Gelatin silver print\"\t\"9 3/4 x 6 7/16' (24.8 x 16.4 cm)\"\t\"2006-05-11\"\t\"Purchase\"\t\"N\"\t\"Photography\"\t\"Photograph\"\t\"397.2006\"\t\t\t\"24.8\"\t\t\"16.4\"\t\t\t\n",
    "103321\t\"Untitled (page from Sump)\"\t25520\t\"Jerome Neuner\"\t1994\t\"Page with chromogenic color print and text\"\t\"12 x 9 1/2' (30.5 x 24.1 cm)\"\t\"2006-05-11\"\t\"E.T. Harmax Foundation Fund\"\t\"N\"\t\"Photography\"\t\"Photograph\"\t\"415.2006.12\"\t\t\t\"30.4801\"\t\t\"24.13\"\t\t\t\n",
    "10\t\"The Manhattan Transcripts Project, New York, New York, Episode 1: The Park\"\t7056\t\"Bernard Tschumi\"\t\t\"Gelatin silver photograph\"\t\"14 x 18' (35.6 x 45.7 cm)\"\t\"1995-01-17\"\t\"Purchase and partial gift of the architect in honor of Lily Auchincloss\"\t\"Y\"\t\"Architecture & Design\"\t\"Architecture\"\t\"3.1995.11\"\t\t\t\"35.6\"\t\t\"45.7\"\t\t\t\n",
    "*/\"\"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db = SQLDatabase.from_uri(\n",
    "    RDS_URI,\n",
    "    include_tables=[\"artists\", \"artworks\"],\n",
    "    sample_rows_in_table_info=3,\n",
    "    custom_table_info=custom_table_info,\n",
    ")\n",
    "\n",
    "# print(db.table_info)\n",
    "\n",
    "db_chain = SQLDatabaseSequentialChain.from_llm(\n",
    "    llm, db, verbose=True, use_query_checker=True, top_k=3\n",
    ")\n",
    "\n",
    "try:\n",
    "    db_chain.run(QUESTION_07)\n",
    "except (ProgrammingError, ValueError) as exc:\n",
    "    print(f\"\\n\\n{exc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize Prompt and Return Intermediate Steps\n",
    "\n",
    "According to LangChain's [documentation](https://python.langchain.com/en/latest/modules/chains/examples/sqlite.html#return-intermediate-steps), \"_You can also return the intermediate steps of the `SQLDatabaseChain`. This allows you to access the SQL statement that was generated, as well as the result of running that against the SQL Database._\"\n",
    "\n",
    "For this part of the demonstration, we will also use a `PromptTemplate`. LangChain's [Prompt Templates](Prompt Templates). According to LangChain, \"_A prompt template refers to a reproducible way to generate a prompt. It contains a text string (“the template”), that can take in a set of parameters from the end user and generate a prompt._\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "_DEFAULT_TEMPLATE = \"\"\"Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer.\n",
    "Use the following format:\n",
    "\n",
    "Question: \"Question here\"\n",
    "SQLQuery: \"SQL Query to run\"\n",
    "SQLResult: \"Result of the SQLQuery\"\n",
    "Answer: \"Final answer here\"\n",
    "\n",
    "Only use the following tables:\n",
    "\n",
    "{table_info}\n",
    "\n",
    "If someone asks for the table art, they really mean the artworks table.\n",
    "\n",
    "Only single quotes in the SQLQuery.\n",
    "\n",
    "Question: {input}\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    input_variables=[\"input\", \"table_info\", \"dialect\"], template=_DEFAULT_TEMPLATE\n",
    ")\n",
    "db_chain = SQLDatabaseChain.from_llm(\n",
    "    llm,\n",
    "    db,\n",
    "    prompt=PROMPT,\n",
    "    verbose=True,\n",
    "    use_query_checker=True,\n",
    "    return_intermediate_steps=True,\n",
    ")\n",
    "\n",
    "try:\n",
    "    result = db_chain(QUESTION_01)\n",
    "    result[\"intermediate_steps\"]\n",
    "except (ProgrammingError, ValueError) as exc:\n",
    "    print(f\"\\n\\n{exc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Few-shot Learning\n",
    "\n",
    "To improve the accuracy of the SQL query, LangChain allows us to use few-shot learning (aka few-shot prompting). According to [Wikipedia](https://en.wikipedia.org/wiki/In-context_learning_(natural_language_processing), \"_In natural language processing, in-context learning, few-shot learning or few-shot prompting is a prompting technique that allows a model to process examples before attempting a task. The method was popularized after the advent of GPT-3 and is considered to be an emergent property of large language models._\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pyyaml chromadb sentence_transformers -Uq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import yaml\n",
    "\n",
    "chain = SQLDatabaseChain.from_llm(\n",
    "    llm, db, verbose=True, return_intermediate_steps=True, use_query_checker=True\n",
    ")\n",
    "\n",
    "\n",
    "def _parse_example(result: Dict) -> Dict:\n",
    "    sql_cmd_key = \"sql_cmd\"\n",
    "    sql_result_key = \"sql_result\"\n",
    "    table_info_key = \"table_info\"\n",
    "    input_key = \"input\"\n",
    "    final_answer_key = \"answer\"\n",
    "\n",
    "    _example = {\n",
    "        \"input\": result.get(\"query\"),\n",
    "    }\n",
    "\n",
    "    steps = result.get(\"intermediate_steps\")\n",
    "    answer_key = sql_cmd_key  # the first one\n",
    "    for step in steps:\n",
    "        # The steps are in pairs, a dict (input) followed by a string (output).\n",
    "        # Unfortunately there is no schema but you can look at the input key of the\n",
    "        # dict to see what the output is supposed to be\n",
    "        if isinstance(step, dict):\n",
    "            # Grab the table info from input dicts in the intermediate steps once\n",
    "            if table_info_key not in _example:\n",
    "                _example[table_info_key] = step.get(table_info_key)\n",
    "\n",
    "            if input_key in step:\n",
    "                if step[input_key].endswith(\"SQLQuery:\"):\n",
    "                    answer_key = sql_cmd_key  # this is the SQL generation input\n",
    "                if step[input_key].endswith(\"Answer:\"):\n",
    "                    answer_key = final_answer_key  # this is the final answer input\n",
    "            elif sql_cmd_key in step:\n",
    "                _example[sql_cmd_key] = step[sql_cmd_key]\n",
    "                answer_key = sql_result_key  # this is SQL execution input\n",
    "        elif isinstance(step, str):\n",
    "            # The preceding element should have set the answer_key\n",
    "            _example[answer_key] = step\n",
    "    return _example\n",
    "\n",
    "\n",
    "example: any\n",
    "try:\n",
    "    result = chain(QUESTION_01)\n",
    "    print(\"\\n*** Query succeeded\")\n",
    "    example = _parse_example(result)\n",
    "except Exception as exc:\n",
    "    print(\"\\n*** Query failed\")\n",
    "    result = {\"query\": QUESTION_04, \"intermediate_steps\": exc.intermediate_steps}\n",
    "    example = _parse_example(result)\n",
    "\n",
    "\n",
    "# print for now, in reality you may want to write this out to a YAML file or database for manual fix-ups offline\n",
    "yaml_example = yaml.dump(example, allow_unicode=True)\n",
    "print(\"\\n\" + yaml_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the corrected examples for few shot prompt examples\n",
    "SQL_SAMPLES = None\n",
    "\n",
    "with open(\"sql_examples.yaml\", \"r\") as stream:\n",
    "    SQL_SAMPLES = yaml.safe_load(stream)\n",
    "\n",
    "# print(SQL_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.chains.sql_database.prompt import _sqlite_prompt, PROMPT_SUFFIX\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.prompts.example_selector.semantic_similarity import (\n",
    "    SemanticSimilarityExampleSelector,\n",
    ")\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"table_info\", \"input\", \"sql_cmd\", \"sql_result\", \"answer\"],\n",
    "    template=\"{table_info}\\n\\nQuestion: {input}\\nSQLQuery: {sql_cmd}\\nSQLResult: {sql_result}\\nAnswer: {answer}\",\n",
    ")\n",
    "\n",
    "examples_dict = SQL_SAMPLES\n",
    "\n",
    "local_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    # This is the list of examples available to select from.\n",
    "    examples_dict,\n",
    "    # This is the embedding class used to produce embeddings which are used to measure semantic similarity.\n",
    "    local_embeddings,\n",
    "    # This is the VectorStore class that is used to store the embeddings and do a similarity search over.\n",
    "    Chroma,  # type: ignore\n",
    "    # This is the number of examples to produce and include per prompt\n",
    "    k=min(3, len(examples_dict)),\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=_sqlite_prompt + \"Here are some examples:\",\n",
    "    suffix=PROMPT_SUFFIX,\n",
    "    input_variables=[\"table_info\", \"input\", \"top_k\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_chain = SQLDatabaseChain.from_llm(\n",
    "    llm,\n",
    "    db,\n",
    "    prompt=few_shot_prompt,\n",
    "    use_query_checker=True,\n",
    "    verbose=True,\n",
    "    return_intermediate_steps=True,\n",
    ")\n",
    "\n",
    "try:\n",
    "    result = db_chain(QUESTION_09)\n",
    "except (ProgrammingError, ValueError) as exc:\n",
    "    print(f\"\\n\\n{exc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain SQL Database Agent\n",
    "\n",
    "According to LangChain [documentation](https://python.langchain.com/en/latest/modules/agents/toolkits/examples/sql_database.html#sql-database-agent), the SQL Database Agent is \"_builds off of `SQLDatabaseChain` and is designed to answer more general questions about a database, as well as recover from errors._\" __NOTE__: _it is not guaranteed that the agent won’t perform DML statements on your database given certain questions. Be careful running it on sensitive data!_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.agents import AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "\n",
    "agent_executor = create_sql_agent(llm=llm, toolkit=toolkit, verbose=True)\n",
    "\n",
    "# try:\n",
    "#     agent_executor.run(\"Describe the artists table\")\n",
    "# except (ProgrammingError, ValueError) as exc:\n",
    "#     print(f\"\\n\\n{exc}\")\n",
    "\n",
    "agent_executor.run(\"Describe the artists table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
